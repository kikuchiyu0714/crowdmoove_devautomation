{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install slackweb\n",
    "#! pip install pandas requests gspread\n",
    "#! pip install beautifulsoup4\n",
    "#! pip install oauth2client\n",
    "#! pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import time\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import slackweb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS\n",
    "import boto3\n",
    "\n",
    "# Connect DynamoDB\n",
    "dynamodb = boto3.resource('dynamodb', region_name='ap-southeast-1') \n",
    "table = dynamodb.Table('mirubuzz-user') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date format\n",
    "import locale\n",
    "locale.setlocale(locale.LC_CTYPE, 'en_US.UTF-8')\n",
    "utc_now = datetime.now(timezone.utc)\n",
    "jst = timezone(timedelta(hours=9))\n",
    "jst_now = utc_now.astimezone(jst)\n",
    "formatted_date = jst_now.strftime(\"%Y年%m月%d日\")\n",
    "#check_date = jst_now.strftime(\"%Y/%m/%d\")\n",
    "check_date = \"2024/09/15\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the function to convert text file\n",
    "\n",
    "def clean_job_offer_container(job_offer_container):\n",
    "    raw_text = str(job_offer_container)\n",
    "\n",
    "    # Delete <div data=\" and \" id=\"jobOfferSearchContainer\"></div>\n",
    "    cleaned_text = raw_text.strip()\n",
    "    if cleaned_text.startswith('<div data=\"'):\n",
    "        cleaned_text = cleaned_text[len('<div data=\"'):]\n",
    "    if cleaned_text.endswith('\" id=\"jobOfferSearchContainer\"></div>'):\n",
    "        cleaned_text = cleaned_text[:-len('\" id=\"jobOfferSearchContainer\"></div>')]\n",
    "\n",
    "    # Replace\n",
    "    replaced_text = cleaned_text.replace('&quot;', '\"')\n",
    "    replaced_text = replaced_text.replace('&amp;', '&')\n",
    "\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the function to convert json file\n",
    "\n",
    "def parse_json_file(raw_text):\n",
    "    try:\n",
    "        json_data = json.loads(raw_text)\n",
    "        #print(\"Success convert json\")\n",
    "        return json_data\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error convert json\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the function to create user list\n",
    "\n",
    "def create_user_list(id):\n",
    "    url = 'https://crowdworks.jp/public/jobs/' + str(id)\n",
    "\n",
    "    # Try to get the number of total pages\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # find json data\n",
    "    user_links = soup.find_all('a', class_='username')\n",
    "    users = []\n",
    "    duplicate_users = []\n",
    "    base_url = \"https://crowdworks.jp\"\n",
    "\n",
    "    # User list\n",
    "    for user_link in user_links:\n",
    "        user_info = {\n",
    "        'アカウントID': user_link.text,\n",
    "        'プロフィールURL': base_url + user_link['href']\n",
    "        }\n",
    "        \n",
    "        # User check\n",
    "        response = table.get_item(\n",
    "            Key={\n",
    "                'アカウントID': user_link.text  # PK\n",
    "            }\n",
    "        )\n",
    "        if 'Item' in response:\n",
    "            #print(response['Item'])\n",
    "            duplicate_users.append(user_info)\n",
    "        else:\n",
    "            users.append(user_info)\n",
    "    print(\"duplicate_users:\", len(duplicate_users))\n",
    "    #print(\"new_users:\", len(users))\n",
    "\n",
    "    return users\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the function to create dataframe\n",
    "\n",
    "def extract_job_offers_to_dataframe(json_data):\n",
    "\n",
    "    df_user_list = []\n",
    "    job_offers = json_data.get('searchResult', {}).get('job_offers', [])\n",
    "    \n",
    "    for offer in job_offers:\n",
    "        job_offer = offer.get('job_offer', {})\n",
    "        id = job_offer.get('id')\n",
    "        # Create user list\n",
    "        user_list = create_user_list(id)\n",
    "        df = pd.DataFrame(user_list)\n",
    "        df['リスト作成元URL'] = 'https://crowdworks.jp/public/jobs/' + str(job_offer.get('id'))\n",
    "        df['掲載日'] = job_offer.get('last_released_at')\n",
    "        df['掲載日'] = df['掲載日'].str.split('T').str[0]\n",
    "        df['応募期限'] = job_offer.get('expired_on')\n",
    "        \n",
    "        df_user_list.append(df)\n",
    "    \n",
    "    # Convert list into DataFrame\n",
    "    merged_df_user = pd.concat(df_user_list, ignore_index=True)\n",
    "    \n",
    "    return merged_df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the function to get total page size\n",
    "\n",
    "def find_total_pages(json_data):\n",
    "\n",
    "    total_pages = json_data.get('searchResult', {}).get('page', []).get('total_page', 0)\n",
    "    \n",
    "    return total_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the function to get data and save as CSV file\n",
    "\n",
    "def fetch_all_pages_and_save(url, category_name):\n",
    "\n",
    "    # Try to get the number of total pages\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # find json data\n",
    "    job_offer_container = soup.find('div', id=\"jobOfferSearchContainer\")\n",
    "    \n",
    "    # Convert json file\n",
    "    cleaned_job_offer_data = clean_job_offer_container(job_offer_container)\n",
    "    json_data = parse_json_file(cleaned_job_offer_data)\n",
    "\n",
    "    # Find the number of page\n",
    "    total_pages = find_total_pages(json_data)\n",
    "\n",
    "    df_list = []\n",
    "    #for n in range(1, total_pages + 1):\n",
    "    for n in range(1, 2):\n",
    "        print('page:', n)\n",
    "        new_url = url + \"&page=\" + str(n)\n",
    "        response = requests.get(new_url)\n",
    "        html_content = response.text\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # find json data\n",
    "        job_offer_container = soup.find('div', id=\"jobOfferSearchContainer\")\n",
    "        \n",
    "        # Convert json file\n",
    "        cleaned_job_offer_data = clean_job_offer_container(job_offer_container)\n",
    "        json_data = parse_json_file(cleaned_job_offer_data)\n",
    "\n",
    "        # Create dataframe\n",
    "        df = extract_job_offers_to_dataframe(json_data)\n",
    "        df_list.append(df)\n",
    "\n",
    "    # Merge and save as CSV\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    merged_df['大カテゴリ'] = category_name\n",
    "    merged_df['小カテゴリ'] = category_name\n",
    "    merged_df['アポ獲得'] = None\n",
    "    merged_df['リスト内重複'] = None\n",
    "    merged_df['最終送信日'] = None\n",
    "    merged_df['送信可否'] = None\n",
    "    merged_df['対象URL'] = None\n",
    "    merged_df['送信文面'] = None\n",
    "    merged_df['K'] = None\n",
    "    merged_df['L'] = None\n",
    "    merged_df['M'] = None\n",
    "    merged_df['日付'] = None\n",
    "    merged_df['O'] = None\n",
    "    merged_df['P'] = None\n",
    "    merged_df['Q'] = None\n",
    "    merged_df['R'] = None\n",
    "    merged_df['S'] = None\n",
    "    merged_df['リスト作成日'] = check_date\n",
    "    #merged_df.to_csv(f'{category_name}.csv', index=False)\n",
    "    #print(merged_df)\n",
    "    return merged_df[['アポ獲得','リスト内重複','最終送信日','送信可否','対象URL','アカウントID','プロフィールURL',\n",
    "                      '送信文面','大カテゴリ','小カテゴリ','K','L','M','日付','O','P','Q','R','S','リスト作成元URL','掲載日','応募期限','リスト作成日']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SS, GDrive\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "kano_json = { \n",
    "            \"type\": \"service_account\",\n",
    "            \"project_id\": \"impressive-hall-390206\",\n",
    "            \"private_key_id\": \"ef3da66bc82fde7e9eed4b0c6a5f6d5d0b3846d6\",\n",
    "            \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvwIBADANBgkqhkiG9w0BAQEFAASCBKkwggSlAgEAAoIBAQCkPQ5zsVUhlKtX\\nmL/Y8xZelG6hZ+Vhq1bM5PjkgGOK5UZB5lVF4yRqbqR4Cir4lwUNstzKCA/5hcKj\\n5Ewjx3c7lpSmZEXM4zOWt88o+eiQquRYz3V7a9zI/vx3xCibbzfAprkqu9P7NlkT\\n8kQCRonpyhcxewVhLDYwPqSKQZ0cWWB6bSMYXG6A4PeWyEQDcUDQF4Vhd/AbqJDP\\nUe7fLPpxzlgfGTW4rSCjgM02lrBPd57DC2LgZ8YVyK91TBLysA03h+KOPK6trEz+\\n7ltDsL/ETPMvecx+7msqZSSfT21AEsU6HQByicxFu6FUadM88ehs31SYoIKUN5TC\\nh6E9fq0rAgMBAAECggEARZZ5IRvp7iiH0L2vy8Rzne9WUJ0s2401YetCac7cXmV2\\nt0VYrBvpug7XMOVd/6Y9ReibFB8GZbr/FWINwLsrEdxjb3zc9krt+NY4uCvrFiDS\\nT67XIEw7aA5h+nzql7Ev9jiuDCU5VB9a7tCfcDdjB+PQn+54AQwyiY6BOPNEFlY6\\nEpWqCWNUxkous1fz1TN/qwZDfE8rzXc4hWV1PXCU4/4Av1jPK5TfHlERkKDKzUck\\nQCkT0t9X3dmNSEUeLKXIWjeRFYKML4z2GE36/FTF+GZ0HA6mfjdaoqjJT8mybKRQ\\nJ365ZrmFTx2O01lLO7koC/IwGmlAfEzwHVzBk1LfAQKBgQDb7ulRQOdaWO8yxqY9\\nfjT5zjQzc7L7bpwkSTAoRRxCw/Nn24Olgg+ywJCg+JiLIHUluBPuPcTGCAePm2F5\\n3ClnaKsy3/RKncuyc4+Ae6rvWs6yqLUoNmN01uiYIFY4goAXwyJFMp7OsK1/akk2\\nJxWywpPndFKbeVDi3YOVK+AGUQKBgQC/LAGHEFiNikSfS4kkHz1pnJGwKaIRsTmB\\nkzR8KEh0OdBGNjhs/gIm+sJMh99btKJIl8meH1NSGBEeW/8KzOIOdwWW2kfJAwiZ\\nnF7AIoVjIoBGjRXlJFl3J93LLnrrOR9bHsevePn/yfvvKdmHIlufKPu8FwQfQSEk\\nHkcZauUQuwKBgQCTrL7jPSZbJt4uBO642ZZuqcOpTKXAaAvV3YLFd2o7dmFouh+S\\nMVujFePHAkVDHd8rHYfcb4NByUByb82qymbOtZxGg9P/iiatQyT3C5LCNwIVOmyx\\nfJuZZ3g0NXpPZWjnC7JmLlAtzroglNhl0Sajqj0vq46QMIxcWIqyzgwVkQKBgQCl\\n7Nn+ko9peiMJZ5RGh97TtZM1pU0HshzJfCzHvmb0ieFdr13WK7lOf8L4jc2tWOCp\\nxSS3W1UEIeNpyEta4m0qRN/TCO3ZaAqk2PXcKZpAawePNJFWavBD3ZRB77u8Qb4X\\nZmXGxWenPXavJFGrWoTPZdDodcmcHvlW0fi/9OmQVQKBgQC6vHMd7EbeJd8btMNT\\n+jqgjMMy/BBc0QZziRGLHZzMFRymv+8yD33dcosh7lt6FkgNr5Sfl1dB258bLfyw\\nyQ54iMsdeKXqiqAVfSyQ89rA/mCzYIuBZhOnp133w1ykUVVaRmLwwj6eW14yMTeD\\npC3va1+egohwGnqAv3c0Lgl8OA==\\n-----END PRIVATE KEY-----\\n\",\n",
    "            \"client_email\": \"python-g-sheet-g-drive@impressive-hall-390206.iam.gserviceaccount.com\",\n",
    "            \"client_id\": \"112741064384026789031\",\n",
    "            \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "            \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "            \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "            \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/python-g-sheet-g-drive%40impressive-hall-390206.iam.gserviceaccount.com\",\n",
    "            \"universe_domain\": \"googleapis.com\"\n",
    "            }\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_dict(kano_json, scope)\n",
    "gc = gspread.authorize(credentials)\n",
    "\n",
    "# Template sheet\n",
    "SOURCE_SPREADSHEET_KEY = \"1prs3Hg7pxG57TwvfxKUWTIh2afGFBqgaNaKu1vHIN9Q\"\n",
    "SHEET_NAME = 'Applyer'\n",
    "\n",
    "# Management sheet\n",
    "PROJECT_SPREADSHEET_KEY = \"1Q06UHepoYMlc5fGeRAhBaQy75SePyBYbLtscnfFfWzU\"\n",
    "PROJECT_SHEET_NAME = \"狩野_スカウトリスト作成_予実管理\"\n",
    "project_workbook = gc.open_by_key(PROJECT_SPREADSHEET_KEY)\n",
    "project_worksheet = project_workbook.worksheet(PROJECT_SHEET_NAME)\n",
    "project_data = project_worksheet.get_all_values()\n",
    "\n",
    "# Store output list\n",
    "TOTAL_SPREADSHEET_KEY = \"1HWDl2joVX_irbfG6mQ46zoIfXZ4TEYFZbX9XDpSiL08\"\n",
    "TOTAL_SHEET_NAME = \"シートまとめ\"\n",
    "total_workbook = gc.open_by_key(TOTAL_SPREADSHEET_KEY)\n",
    "total_worksheet = total_workbook.worksheet(TOTAL_SHEET_NAME)\n",
    "total_worksheet_url = total_workbook.url\n",
    "\n",
    "# Slack\n",
    "slack = slackweb.Slack(url=\"https://hooks.slack.com/services/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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['731', '732', '733', '734', '735']\n",
      "['https://crowdworks.jp/public/jobs/search?category_id=267&hide_expired=true&order=popular&payment_type=fixed_price%2Chourly', 'https://crowdworks.jp/public/jobs/search?category_id=230&hide_expired=true&order=popular&payment_type=fixed_price%2Chourly%2Ctask', 'https://crowdworks.jp/public/jobs/search?category_id=225&hide_expired=true&order=popular&payment_type=fixed_price%2Chourly%2Ctask', 'https://crowdworks.jp/public/jobs/search?category_id=226&hide_expired=true&order=popular&payment_type=fixed_price%2Chourly%2Ctask', 'https://crowdworks.jp/public/jobs/search?category_id=263&hide_expired=true&order=popular&payment_type=fixed_price%2Chourly%2Ctask']\n",
      "['事務・カンタン作業', 'ホームページ制作・Webデザイン', 'ビジネス・マーケティング・企画', 'システム開発', '音楽・音響・ナレーション']\n"
     ]
    }
   ],
   "source": [
    "# Append list from management sheet\n",
    "exe_rows = []\n",
    "for idx, row in enumerate(project_data):\n",
    "    if idx == 0:  # Skip header\n",
    "        continue\n",
    "    b_value = row[1]\n",
    "    f_value = row[5]\n",
    "    if b_value == check_date and f_value != \"完了\":\n",
    "        exe_rows.append(idx + 1)\n",
    "\n",
    "raw_project_data = []\n",
    "url_num_data = []\n",
    "project_data_list = []\n",
    "small_category_list = []\n",
    "\n",
    "for row_number in exe_rows:\n",
    "    row = project_worksheet.row_values(row_number)\n",
    "    if len(row) > 5 and row[5] == '':  # F列（6列目、0-indexで5）の空白チェック\n",
    "        if len(row) >= 5:  # C列とE列が存在するか確認\n",
    "            a_value = row[0]  # A列（0-indexで2）\n",
    "            c_value = row[2]  # C列（0-indexで2）\n",
    "            e_value = row[4]  # E列（0-indexで4）\n",
    "            raw_project_data.append((a_value,c_value, e_value))\n",
    "\n",
    "# Show result\n",
    "try_num = len(exe_rows)\n",
    "for pp in range(try_num):\n",
    "    url_num_data.append(raw_project_data[pp][0])\n",
    "for tt in range(try_num):\n",
    "    project_data_list.append(raw_project_data[tt][1])\n",
    "for yyy in range(try_num):\n",
    "    small_category_list.append(raw_project_data[yyy][2])\n",
    "print(url_num_data)\n",
    "print(project_data_list)\n",
    "print(small_category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_execute(func, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except gspread.exceptions.APIError as e:\n",
    "        retries = 2\n",
    "        for _ in range(retries):\n",
    "            if '500' in str(e):\n",
    "                time.sleep(5) \n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except gspread.exceptions.APIError as e:\n",
    "                    continue\n",
    "        # 再試行後もエラーが解決しない場合、Slackに通知\n",
    "        slack_text = f\"\"\"<!here> \n",
    "                        2回リトライしてもスプシのサーバーエラーで実行できませんでした。\n",
    "                        {e}\n",
    "                    \"\"\"\n",
    "        slack.notify(text=slack_text)\n",
    "    except Exception as e:\n",
    "        slack_text = f\"\"\"<!here> \n",
    "                    予期しないエラーが発生しました。\n",
    "                    {e}\n",
    "                    \"\"\"\n",
    "        slack.notify(text=slack_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop\n",
    "\n",
    "for c in range(try_num):\n",
    "    \n",
    "    # newSheetTitle = \"ApplyerList_#\" + str(url_num_data[c]) + \"_\" + small_category_list[c]\n",
    "    newSheetTitle = \"TestApplyerList_#\" + str(url_num_data[c]) + \"_\" + small_category_list[c]\n",
    "    copied_sheet = safe_execute(lambda: gc.copy(SOURCE_SPREADSHEET_KEY, title=newSheetTitle + formatted_date, copy_permissions=False))        \n",
    "    copied_sheet.share(\"tadanosin0729@gmail.com\", perm_type='user', role='writer')\n",
    "    copied_sheet.share(None, perm_type='anyone', role='writer')\n",
    "    copied_sheet_url = copied_sheet.url\n",
    "    copied_sheet_title = copied_sheet.title\n",
    "\n",
    "    # 転記先のGSSを開く\n",
    "    worksheet = copied_sheet.worksheet(SHEET_NAME)\n",
    "    total_last_row = safe_execute(lambda: len(total_worksheet.col_values(1)))\n",
    "    total_next_row = total_last_row + 1\n",
    "    safe_execute(lambda: total_worksheet.update_cell(total_next_row, 1, url_num_data[c]))\n",
    "    safe_execute(lambda: total_worksheet.update_cell(total_next_row, 2, copied_sheet_title))\n",
    "    safe_execute(lambda: total_worksheet.update_cell(total_next_row, 3, copied_sheet_url))\n",
    "    safe_execute(lambda: total_worksheet.update_cell(total_next_row, 4, formatted_date))\n",
    "\n",
    "    # 開始時間を記載\n",
    "    safe_execute(lambda: project_worksheet.update_cell(exe_rows[c], 7, datetime.now().strftime('%H:%M:%S')))\n",
    "    \n",
    "    # Target category\n",
    "    url = project_data_list[c]\n",
    "    category = small_category_list[c]\n",
    "    print('Start Category:', category)\n",
    "    c_df = fetch_all_pages_and_save(url, category)\n",
    "\n",
    "    # Convert\n",
    "    data_list = c_df.values.tolist()\n",
    "    last_row = safe_execute(lambda: len(worksheet.col_values(1)))\n",
    "    start_row = last_row + 1\n",
    "    end_row = start_row + len(c_df) - 1\n",
    "    cell_range = f'A{start_row}:W{end_row}'  # Assuming data has 3 columns\n",
    "    #safe_execute(worksheet.update, cell_range, data_list)\n",
    "    safe_execute(worksheet.update, data_list, cell_range)\n",
    "\n",
    "    # GSS上のステータスを「完了」に更新\n",
    "    safe_execute(lambda: project_worksheet.update_cell(exe_rows[c], 6, \"完了\"))        \n",
    "    # GSS上に終了時間を記載\n",
    "    safe_execute(lambda: project_worksheet.update_cell(exe_rows[c], 8, datetime.now().strftime('%H:%M:%S')))\n",
    "    # GSS上に取得数を記載\n",
    "    num_getdata = safe_execute(lambda: len(worksheet.col_values(6)))\n",
    "    safe_execute(lambda: project_worksheet.update_cell(exe_rows[c], 9, num_getdata))\n",
    "\n",
    "    print(\"Finish\")\n",
    "\n",
    "    refsheet = copied_sheet.worksheet(\"ユニーク\")\n",
    "    newss_getApplyerListnum = safe_execute(lambda: len(refsheet.col_values(3))-1) # 見出し分を引いている\n",
    "    newss_getPrijectListnum = safe_execute(lambda: len(refsheet.col_values(1))-1)  # 見出し分を引いている\n",
    "    slack_text =  f\"\"\"\n",
    "                *スクレイピングが完了しました。* \\n スクレイピング元リンク：　<{url}|{category}> \\n スプシURL：　<{copied_sheet_url}|{copied_sheet_title}>\\n 記事数ユニーク：　{newss_getPrijectListnum}\\n 取得アカウント数ユニーク：　{newss_getApplyerListnum}\\n\\n<{total_worksheet_url}|新規生成スプシ一覧>\n",
    "                \"\"\"\n",
    "    slack.notify(text=slack_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                *スクレイピングが完了しました。* \\n スクレイピング元リンク：\\u3000<https://crowdworks.jp/public/jobs/search?category_id=267&hide_expired=true&order=popular&payment_type=fixed_price%2Chourly|事務・カンタン作業> \\n スプシURL：\\u3000<https://docs.google.com/spreadsheets/d/19GZESGFpuX_4kl1kI3OcSG5Gz9ledf5bPk7gZgWq8VU|TestApplyerList_#731_事務・カンタン作業2024年09月14日>\\n 記事数ユニーク：\\u300048\\n 取得アカウント数ユニーク：\\u3000381\\n\\n<https://docs.google.com/spreadsheets/d/1HWDl2joVX_irbfG6mQ46zoIfXZ4TEYFZbX9XDpSiL08|新規生成スプシ一覧>\\n                '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slack_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack.notify(text=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://hooks.slack.com/services/your-webhook-url\")\n",
    "print(response.status_code)  # 正常なら200が返る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
